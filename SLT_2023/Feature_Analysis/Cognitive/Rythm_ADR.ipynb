{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa52d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ranksums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1112ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a077a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/export/b15/rpapagari/Tianzi_work/ADReSSo_NoVAD_IS2021_dataset/data_ADReSSo_diagnosis_cv10_text_v7_Longformer_TrainDevTest/cv_6/utt2csvpath'\n",
    "train = '/export/b15/rpapagari/Tianzi_work/ADReSSo_NoVAD_IS2021_dataset/data_ADReSSo_diagnosis_cv10_text_v7_Longformer_TrainDevTest/cv_6/train.tsv'\n",
    "dev = '/export/b15/rpapagari/Tianzi_work/ADReSSo_NoVAD_IS2021_dataset/data_ADReSSo_diagnosis_cv10_text_v7_Longformer_TrainDevTest/cv_6/dev.tsv'\n",
    "test = '/export/b15/rpapagari/Tianzi_work/ADReSSo_NoVAD_IS2021_dataset/data_ADReSSo_diagnosis_cv10_text_v7_Longformer_TrainDevTest/cv_6/test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76333d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kruskal(f, task, c, p, c_name, p_name):\n",
    "    for i, title in enumerate(task):\n",
    "        nome = title\n",
    "        f.write(('\\n'+ f'kruskal results for {title} {c_name} {p_name} {stats.kruskal(c[i], p[i]).pvalue} \\n\\n'))\n",
    "\n",
    "\n",
    "def delete_multiple_element(list_object, indices):\n",
    "    indices = sorted(indices, reverse=True)\n",
    "    for idx in indices:\n",
    "        if idx < len(list_object):\n",
    "            list_object.pop(idx)\n",
    "            \n",
    "    return list_object\n",
    "\n",
    "def read_stats_test(file):\n",
    "    \n",
    "    with open(file, 'r') as f:\n",
    "        lista = []\n",
    "        testo = f.readlines()\n",
    "        testo = [line.strip(\"\\n\") for line in testo]\n",
    "\n",
    "        for line in testo:\n",
    "            if line==\"\":\n",
    "                pass\n",
    "            else:\n",
    "                lista.append(line)\n",
    "                \n",
    "    return lista\n",
    "\n",
    "def holm_correction(kruskal):\n",
    "    line_to_remove=[]\n",
    "    values=[]\n",
    "    corrected =[]\n",
    "    final = []\n",
    "    for l in kruskal:\n",
    "        if \"nan\" in l:\n",
    "            line_to_remove.append(kruskal.index(l))\n",
    "    \n",
    "    new_krusk = delete_multiple_element(kruskal, line_to_remove)\n",
    "            \n",
    "    for line in new_krusk:\n",
    "        ok = line.split('vs.')[1]\n",
    "        num = ok.split(\" \")[2]\n",
    "        values.append(float(num))\n",
    "   # values = [x for x in values if isnan(x) == False]\n",
    "    result = statsmodels.stats.multitest.fdrcorrection(values, alpha=0.05, method='indep', is_sorted=False)\n",
    "    num = np.where(result[0] == True)\n",
    "    list_index = ((num)[0]).tolist()\n",
    "\n",
    "    for i in list_index:\n",
    "        corrected.append(result[1][i])\n",
    "    for i in list_index:\n",
    "        final.append(kruskal[i])\n",
    "    \n",
    "    return final, corrected\n",
    "    \n",
    "\n",
    "\n",
    "def data_to_csv(path_trans, train, dev, test):\n",
    "    \n",
    "    path_ordered = []\n",
    "    sentences = []\n",
    "    \n",
    "    read_train = pd.read_csv(train, header=None)\n",
    "    read_dev = pd.read_csv(dev, header=None)\n",
    "    read_test = pd.read_csv(test, header=None)\n",
    "    data = pd.concat([read_train, read_dev, read_test], ignore_index=True)\n",
    "    \n",
    "    read_trans = pd.read_csv(path_trans, header=None)\n",
    "    patients = (data[0].tolist())\n",
    "    labels = (data[1].tolist())\n",
    "    path_to_transcript= read_trans[1].tolist()\n",
    "    \n",
    "    for patient in patients:\n",
    "        for path in path_to_transcript:\n",
    "            if os.path.basename(path).split('.csv')[0] == patient:\n",
    "                path_ordered.append(path)\n",
    "                \n",
    "    for transcript in path_ordered:\n",
    "        with open(transcript, 'r') as f:\n",
    "            transcript_ = f.readlines()\n",
    "        #print(transcript_)\n",
    "            transcript_ = transcript_[0]\n",
    "            sentences.append(transcript_)\n",
    "\n",
    "            \n",
    "    \n",
    "    dict = {'idx': patients, 'label': labels, 'sentence': sentences} \n",
    "    df = pd.DataFrame(dict)\n",
    "    return df\n",
    "    \n",
    "def compute_best_scores(lista):    \n",
    "\n",
    "    values = []\n",
    "    critical = []\n",
    "    final = [] \n",
    "    \n",
    "    for l in lista:\n",
    "        ok = l.split('vs.')[1]\n",
    "        num = ok.split(\" \")[2]\n",
    "        values.append(num)\n",
    "\n",
    "    for value in values:\n",
    "        if float(value) < 0.05:\n",
    "            critical.append(value)\n",
    "\n",
    "    for li in lista:\n",
    "        for cri in critical:\n",
    "            if cri in li:\n",
    "                final.append(li)\n",
    "\n",
    "    return final\n",
    "\n",
    "\n",
    "\n",
    "df = data_to_csv(path, train, dev, test)\n",
    "len(set(df['idx'].tolist()))\n",
    "name=df['idx'].tolist()\n",
    "lab=df['label'].tolist()\n",
    "dictio = {name_:lab_ for name_, lab_ in zip(name, lab)}\n",
    "\n",
    "\n",
    "word_analysis = []\n",
    "path = os.listdir(\"/export/c12/afavaro/Alignment/Address_2021/csvfiles\")\n",
    "print(len(path))\n",
    "for elem in path:\n",
    "    if \"word.csv\" in elem:\n",
    "        word_analysis.append(os.path.join('/export/c12/afavaro/Alignment/Address_2021/csvfiles', elem))\n",
    "\n",
    "\n",
    "base = [os.path.basename(element) for element in word_analysis]\n",
    "names_ = [ele.split('_PAR')[0] for ele in base]\n",
    "len(names_)\n",
    "\n",
    "\n",
    "for element in word_analysis:\n",
    "    participant = pd.read_csv(element)\n",
    "\n",
    "\n",
    "list_of_dataframes = []\n",
    "for element in word_analysis:\n",
    "    participant = pd.read_csv(element)\n",
    "    std = participant.Time.std()\n",
    "    skew = participant.Time.skew()\n",
    "    d = {'Rhythm_std': std,'rhythm_skew': skew} # 'Rhythm_kurt': kurtosis, \n",
    "    df = pd.DataFrame(d, index =[0])\n",
    "    list_of_dataframes.append(df)\n",
    "\n",
    "data = pd.concat(list_of_dataframes, sort=False)\n",
    "data.dropna()\n",
    "data['name'] = names_\n",
    "\n",
    "\n",
    "remove =[]\n",
    "label = []\n",
    "for r in (data['name']):\n",
    "    if r in dictio:\n",
    "        #disorders.append(r)\n",
    "        label.append(dictio[r])\n",
    "    else:\n",
    "        remove.append(r)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3116994",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in remove:\n",
    "    data = data[~data.name.str.contains(e)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59255df2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "remove =[]\n",
    "label = []\n",
    "for r in (data['name']):\n",
    "    if r in dictio:\n",
    "        #disorders.append(r)\n",
    "        label.append(dictio[r])\n",
    "    else:\n",
    "        remove.append(r)\n",
    "       \n",
    "\n",
    "data['lab'] = label\n",
    "\n",
    "\n",
    "grouped = data.groupby(\"lab\") #here we extract the values by category\n",
    "control = grouped.get_group(\"cn\") \n",
    "alzheimer =  grouped.get_group(\"ad\")\n",
    "\n",
    "\n",
    "task = data.columns[0:-2].values.tolist()\n",
    "\n",
    "\n",
    "task = data.columns[0:-2].values.tolist()\n",
    "control_all_feat = np.array([control[feat] for feat in np.array(data.columns[0:-2])])\n",
    "alzhiemer_all_feat = np.array([alzheimer[feat] for feat in np.array(data.columns[0:-2])])\n",
    "\n",
    "\n",
    "\n",
    "with open('/export/b14/afavaro/Addresso_Results/rhythm.txt', 'w') as f:\n",
    "    \n",
    "    kruskal(f, task, control_all_feat, alzhiemer_all_feat, \"controls vs.\", \"alzheimer\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}